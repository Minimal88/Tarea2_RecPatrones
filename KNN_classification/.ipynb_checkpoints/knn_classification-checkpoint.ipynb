{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K- Nearest Neighbours Classification  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "KNN is a simple Classification Algorithm. An object is classified by a majority vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). If k = 1, then the object is simply assigned to the class of that single nearest neighbor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from matplotlib import style\n",
    "from collections import Counter\n",
    "import random\n",
    "style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In this notebook, we implement the algorithm from the basics. For the purpose of visualization, we will first test the model on 2-dimensional data points. Later, we employ the same model on the Iris Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn method (3 neighbors by default)\n",
    "def knn(data,predict,k=3):\n",
    "    \n",
    "    # data is the training set \n",
    "    # predict is a single test data instance\n",
    "    # k is number of nearest neighbors used for classification (user parameter)\n",
    "    \n",
    "    if len(data)>=k:\n",
    "        warnings.warn('K is set to value less than total voting groups!')\n",
    "    \n",
    "    # distances stores distance and label of the training points from the test point\n",
    "    distances = []\n",
    "    for group in data:\n",
    "        for features in data[group]:\n",
    "            euclidean_distance = np.linalg.norm(np.array(features)-np.array(predict))\n",
    "            distances.append([euclidean_distance, group])\n",
    "    \n",
    "    # sort distances in increasing order and take the label of the least k among them\n",
    "    votes = [i[1] for i in sorted(distances)[:k]]\n",
    "    \n",
    "    # find the label which occurs the most and proportion of the its occurence\n",
    "    vote_result = Counter(votes).most_common(1)[0][0]\n",
    "    confidence = Counter(votes).most_common(1)[0][1]/k\n",
    "    return vote_result , confidence   "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Training and Testing against 2 dimensional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('r', 1.0)\n"
     ]
    }
   ],
   "source": [
    "# train set\n",
    "# 3 points each in 2 classes ('k': black, 'r':red)\n",
    "dataset = {'k':[[1,2],[2,3],[3,1]] , 'r':[[6,5],[7,7],[8,6]]}\n",
    "\n",
    "# test instance\n",
    "new_features = [5,7]\n",
    "\n",
    "result = knn(dataset,new_features,3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEJCAYAAAC+I6F6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAGS5JREFUeJzt3X9slPUBx/FPr0c5KrBiW2vUIqG0Yk9ROCJodLgQioauRzDDo9Y58ccKkoUZFXH+grmxDXRGnPI7qbblRgTNtf7AxsCgEgY7FzG3LB4jJRADlmZlK90Fe3f7w9ms/Ojd8e3d0wfer4Q/7nm+D8/nOUg/z/d5nutldXZ2xgUAwAVyWB0AAGBvFAkAwAhFAgAwQpEAAIxQJAAAIxQJAMAIRQIAMEKRAACMDMoiCYfDVkcwZvdjIL+1yG8t8qdmUBYJAMA+KBIAgBGKBABghCIBABihSAAARigSAIARp9UBAGBQiEblDASUs3mzyjo6NCw/X6erq9VTVSU5OOfuT8IiufHGG3XkyJGzlldUVGjLli1pCQVcyrLa2jTy00+VNWSI4mPGWB3nkpDV3q5cn0/ZoZCyIhEN+d9y565diq5erW6/X/HCQkszDmYJi2THjh2KRqO9r48dO6Y777xTs2fPTmsw4JJz8qRy589X9uefq+zECcUKChS96SZ1b9okfe97Vqe7eMViyvX55AwGz1qVFYnIGQwq1+fTqZYWZibnkfBdKSgoUFFRUe+flpYWjRgxgiIBBlju/Pka8skncpw4IUlynDihIZ98otz58y1OdnFzBgLKDoX6HZMdCsnZ3JyhRPaTUr3G43G9/fbbuvfee5Wbm5uuTMAlJ6utTdmff37Oddmff66strbMBrqE5DQ2KisS6XdMViSinPr6DCWyn5Rutu/YsUOHDx/W/fffn3Cs6e96sfvvupHsfwzkz5yRn36qsv/NRM7kOHFCx/70J/3rm28ynMqMXd7/so6O3nsi/flPR4dtjkka+Pe/tLT0vOtSKpK6ujpNmjRJEyZMMNppIuFw2Gj7wcDux0D+zMoaMkSxgoLey1r/L1ZQoCunTVORjW682+n9H5afn/Q4uxxTpt//pC9ttbe364MPPtADDzyQzjzAJSk+ZoyiN910znXRm27i6a00Ol1drbjL1e+YuMul0zU1GUpkP0kXSUNDg4YOHao5c+akMw9wyeretEnfTJ+uWEGBpG9nIt9Mn/7tU1tIm56qKkXd7n7HRN1u9VRWZiiR/SR1aSsej+utt97SnDlzNGLEiHRnAi5N3/ueurduVVZbm4796U+6cto0ZiKZ4HCo2+/v8zmS78RdLkXdbnX7/Tz624+kimT37t06dOiQ1q9fn+48wCUvPmaM/vXNN7a6J2J38cJCnWppkbOpSTkNDfrPd59sr6n5diZCifQrqSL5/ve/r87OznRnAQDrOBzq8XrV4/Xa6mGBwYCaBQAYoUgAAEYoEgCAEYoEAGCEIgEAGKFIAABGKBIAgBGKBABghCIBABihSAAARigSAIARigQAYIQiAQAYoUgAAEYoEgCAEYoEAGCEIgEAGKFIAABGKBIAgBGKBABghCIBABihSAAARigSAICRpIrk2LFjqq2tVUlJiYqKijRlyhS1tramOxsAIFnRqJzvvqvcuXNVVlur3Llz5XzvPSkWS/uunYkGdHZ2aubMmZo6daq2bNmi/Px8HT58WIWFhWkPBwBILKu9Xbk+n7JDIWVFIhryv+XOXbsUXb1a3X6/4mn8mZ2wSF577TVdeeWVWrt2be+yMWPGpC0QACAFsZhyfT45g8GzVmVFInIGg8r1+XSqpUVypOduRsK/9f3335fH49GDDz6ocePG6fbbb9e6desUj8fTEggAkDxnIKDsUKjfMdmhkJzNzWnLkLBI2tratHHjRo0ZM0Zbt25VbW2tli1bpvXr16ctFAAgOTmNjcqKRPodkxWJKKe+Pm0Zsjo7O/udWhQWFmrixIn6+OOPe5ctX75czc3N2rdv33m3C4fDA5cSAHBOZbW1GnmOy1pn+pfHoy/XrLng/ZSWlp53XcJ7JEVFRbruuuv6LCsrK9PRo0cveKeJhMNho+0HA7sfA/mtRX5r2Sn/sPz8pMel65gSXtqaOnWqDh482GfZwYMHVVxcnJZAAIDkna6uVtzl6ndM3OXS6ZqatGVIWCQLFy7U/v37tWrVKh06dEjvvfee1q1bp4cffjhtoQAAyempqlLU7e53TNTtVk9lZdoyJCySSZMmqaGhQe+++65uvfVW/fKXv9QzzzxDkQDAYOBwqNvvV4/Hc9bMJO5yqcfjUbffn7ZHf6Uk7pFI0syZMzVz5sy0hQAAXLh4YaFOtbTI2dSknIYG/aejQ8Py83W6pubbmUgaS0RKskgAAIOcw6Eer1c9Xm/GHxbglzYCAIxQJAAAIxQJAMAIRQIAMEKRAACMUCQAACMUCQDACEUCADBCkQAAjFAkAAAjFAkAwAhFAgAwQpEAAIxQJAAAIxQJAMAIRQIAMEKRAACMUCQAACMUCQDACEUCADBCkQAAjFAkAAAjTqsDALhIRKNyBgLK2bxZZR0dGpafr9PV1eqpqpIcnLNezBIWyYoVK/Tb3/62z7IrrrhCX375ZdpCAbCXrPZ25fp8yg6FlBWJaMj/ljt37VJ09Wp1+/2KFxZamhHpk9SMpLS0VM3Nzb2vs7Oz0xYIgM3EYsr1+eQMBs9alRWJyBkMKtfn06mWFmYmF6mkisTpdKqoqCjdWQDYkDMQUHYo1O+Y7FBIzubmby9z4aKT1OlBW1ubrr/+ek2YMEHz589XW1tbmmMBsIucxkZlRSL9jsmKRJRTX5+hRMi0rM7Oznh/A1paWtTV1aXS0lKdOHFCK1euVDgc1t69e3X55Zefd7twODzgYQEMPmW1tRp5jstaZ/qXx6Mv16zJQCKkQ2lp6XnXJby0NWPGjD6vJ0+erJtvvlmNjY1atGjRBe00kXA4bLT9YGD3YyC/teyUf1h+ftLj7HJMdnr/zyXT+VO+8zV8+HCNHz9ehw4dSkceADZzurpacZer3zFxl0una2oylAiZlnKRRCIRhcNhbr4DkCT1VFUp6nb3OybqdqunsjJDiZBpCYvk2WefVWtrq9ra2vSXv/xFDzzwgLq7uzVv3rxM5AMw2Dkc6vb71ePxnDUzibtc6vF41O338+jvRSzhPZKvvvpKDz/8sDo6OlRQUKDJkyerpaVFo0ePzkQ+ADYQLyzUqZYWOZualNPQoP9898n2mppvZyKUyEUtYZFs2rQpEzkA2J3DoR6vVz1er+1vViM1nCYAAIxQJAAAIxQJAMAIRQIAMEKRAACMUCQAACMUCQDACEUCADBCkQAAjFAkAAAjFAkAwAhFAgAwQpEAAIxQJAAAIxQJAMAIRQIAMEKRAACMUCQAACMUCQDACEUCADBCkQAAjFAkAAAjFAkAwAhFAgAwknKRvPzyy8rLy9OTTz6ZjjwAAJtJqUj279+vuro6ud3udOUBANhM0kVy8uRJPfLII1q9erXy8vLSmQkAYCNJF8nixYvl9Xo1bdq0dOYBANhMVmdnZzzRoLq6Om3atEktLS3KycnRrFmzVF5erpUrV553m3A4PKBBAQDWKS0tPe86Z6KNw+Gwli9frg8//FA5OTkDstNk9mmy/WBg92Mgv7XIby3ypyZhkezbt08dHR269dZbe5dFo1Ht2bNHmzZt0ldffaWhQ4emNSQAYPBKWCSzZs3SxIkT+yx77LHHVFJSoscffzylWQoA4OKTsEjy8vLOekorNzdXo0aNUnl5edqCAQDsgU+2AwCMJJyRnMv7778/0DkAADbFjAQAYIQiAQAYoUgAAEYoEgCAEYoEAGCEIgEAGKFIAABGKBIAgBGKBABghCIBABihSAAARigSAIARigQAYIQiAQAYoUgAAEYoEgCAEYoEAGCEIgEAGKFIAABGKBIAgBGKBABghCIBABihSAAARhIWyfr163XbbbepuLhYxcXFmjFjhrZv356JbLYTjUb17rvvau7cuaqtrdXcuXP13nvvKRaLWR0NANLGmWjAVVddpWXLlqmkpESxWEybN2/Wfffdp507d+qGG27IREZbaG9vl8/nUygUUiQS6V2+a9curV69Wn6/X4WFhRYmBID0SDgjmTVrlmbMmKGxY8dq3Lhxeu655zR8+HDt378/E/lsIRaLyefzKRgM9ikRSYpEIgoGg/L5fMxMAFyUUrpHEo1GtXXrVp06dUq33HJLujLZTiAQUCgU6ndMKBRSc3NzhhIBQOYkVSShUEhXX321rrjiCv385z9XfX293G53urPZRmNj41kzkTNFIhHV19dnKBEAZE5WZ2dnPNGg06dP6+jRozp58qQCgYDq6urU3Nys8vLy824TDocHNOhgVltbq2AwmHCcx+PRmjVrMpAIAAZWaWnpedclvNkuSTk5ORo7dqwkaeLEifrss8/0xhtv6PXXX7+gnSYSDoeNts+0/Pz8pMfZ5bjs9m9wJvJbi/zWynT+C/ocSSwW0+nTpwc6i21VV1fL5XL1O8blcqmmpiZDiQAgcxIWyYsvvqg9e/bo8OHDCoVCWrZsmVpbW/WjH/0oE/lsoaqqKuE9I7fbrcrKygwlAoDMSXhp6/jx43r00Uf19ddfa+TIkXK73XrnnXc0ffr0TOSzBYfDIb/ff87PkbhcLrndbvn9fjkc/CIBABefhEXy5ptvZiKH7RUWFqqlpUVNTU1qaGhQR0eH8vPzVVNTo8rKSkoEwEUrqZvtSI7D4ZDX65XX67X9zToASBanyQAAIxQJAMAIRQIAMEKRAACMUCQAACMUCQDACEUCADBCkQAAjFAkAAAjFAkAwAhFAgAwQpEAAIxQJAAAIxQJAMAIRQIAMEKRAACMUCQAACMUCQDACEUCADBCkQAAjFAkAAAjFAkAwIjT6gDfiUajCgQC2rx5szo6OpSfn6/q6mpVVVXJ4aDvAGCwSlgkr7zyipqamnTw4EHl5ORo8uTJeuGFF1ReXj5gIdrb2+Xz+RQKhRSJRHqX79q1S6tXr5bf71dhYeGA7Q8AMHASnuq3trbqoYce0vbt2xUIBOR0OjV79mz985//HJAAsVhMPp9PwWCwT4lIUiQSUTAYlM/nUywWG5D9AQAGVsIZybZt2/q8Xrt2rUaPHq29e/fq7rvvNg4QCAQUCoX6HRMKhdTc3Kyqqirj/QEABlbKNx+6uroUi8WUl5c3IAEaGxvPmomcKRKJqL6+fkD2BwAYWFmdnZ3xVDb4yU9+on/84x/auXOnsrOzzzsuHA4n9ffV1tYqGAwmHOfxeLRmzZqkcwIABk5pael516X01NYzzzyjvXv36qOPPuq3RBLt9P/l5+cnPS7Zv3MwCIfDtsp7JvJbi/zWIn9qkr60tXTpUm3dulWBQEBjxowZsADV1dVyuVz9jnG5XKqpqRmwfQIABk5SRbJkyRK98847CgQCKisrG9AAVVVVcrvd/Y5xu92qrKwc0P0CAAZGwiJ54okn1NjYqA0bNigvL0/Hjx/X8ePH1dXVNTABHA75/X55PJ6zZiYul0sej0d+v58PJQLAIJXwHsmGDRskSV6vt8/yJUuWaOnSpQMSorCwUC0tLWpqalJDQ0PvJ9trampUWVlJiQDAIJawSDo7OzORQw6HQ16vV16v1/Y3ugDgUsKpPgDACEUCADBCkQAAjFAkAAAjFAkAwAhFAgAwQpEAAIxQJAAAIxQJAMAIRQIAMEKRAACMUCQAACMUCQDACEUCADBCkQAAjFAkAAAjFAkAwAhFAgAwQpEAAIxQJAAAIxQJAMAIRQIAMEKRAACMOK0OgMEjGo0qEAho8+bN6ujoUH5+vqqrq1VVVSWHg3MOAOeW1E+HTz/9VD6fT9dff73y8vLU0NCQ7lzIsPb2dlVUVGjBggX6+OOPFQwG9fHHH6u2tlYzZsxQe3u71REBDFJJFcmpU6dUXl6u3/zmNxo2bFi6MyHDYrGYfD6fgsGgIpFIn3WRSETBYFA+n0+xWMyihAAGs6SKpKKiQs8//7y8Xi+XOC5CgUBAoVCo3zGhUEjNzc0ZSgTATmgFqLGx8ayZyJkikYjq6+szlAiAnaTtZns4HLZ0+8HALsfQ0dGR9Di7HJNkn/f/fMhvLfL3VVpaet51aSuS/naaSDgcNtp+MLDTMeTn5yc9zi7HZKf3/1zIby3yp4ZLW1B1dbVcLle/Y1wul2pqajKUCICdUCRQVVWV3G53v2PcbrcqKyszlAiAnSRVJF1dXTpw4IAOHDigWCymo0eP6sCBAzpy5Ei68yEDHA6H/H6/PB7PWTMTl8slj8cjv9/PE3sAzimpeyR//etf9cMf/rD39YoVK7RixQrNmzdPb775ZtrCIXMKCwvV0tKipqYmNTQ09H6yvaamRpWVlZQIgPNKqkjuuOMOdXZ2pjsLLOZwOOT1euX1em1/sxFA5nCaCQAwQpEAAIxQJAAAI1mdnZ1xq0MAAOyLGQkAwAhFAgAwQpEAAIxQJAAAIxQJAMDIoCoSO383/CuvvKIf/OAHKi4uVklJie6991797W9/szpW0tavX6/bbrtNxcXFKi4u1owZM7R9+3arY12wl19+WXl5eXryySetjpKUFStWKC8vr8+fsrIyq2Ol7NixY6qtrVVJSYmKioo0ZcoUtba2Wh0rKTfeeONZ/wZ5eXmaO3eu1dGSEo1G9dJLL2nChAkqKirShAkT9NJLL6mnpyft+07b95FciO++G37evHmqra21Ok5KWltb9dBDD2nSpEmKx+P69a9/rdmzZ+vPf/6zRo0aZXW8hK666iotW7ZMJSUlisVi2rx5s+677z7t3LlTN9xwg9XxUrJ//37V1dUl/I3Gg01paWmfrzPOzs62ME3qOjs7NXPmTE2dOlVbtmxRfn6+Dh8+rMLCQqujJWXHjh2KRqO9r48dO6Y777xTs2fPtjBV8l599VVt2LBBb775psrLyxUKhbRgwQLl5OToqaeeSuu+B1WRVFRUqKKiQpK0cOFCi9OkZtu2bX1er127VqNHj9bevXt19913W5QqebNmzerz+rnnntPGjRu1f/9+WxXJyZMn9cgjj2j16tX63e9+Z3WclDidThUVFVkd44K99tpruvLKK7V27dreZWPGjLEuUIoKCgr6vH777bc1YsQI2xTJvn37dNddd/X+vLn22mt19913KxgMpn3fg+rS1sWkq6tLsVhMeXl5VkdJWTQa1datW3Xq1CndcsstVsdJyeLFi+X1ejVt2jSro6Ssra1N119/vSZMmKD58+erra3N6kgpef/99+XxePTggw9q3Lhxuv3227Vu3TrF4/b7zHM8Htfbb7+te++9V7m5uVbHScrUqVPV2tqqL7/8UpL097//Xbt379aMGTPSvu9BNSO5mDz99NO68cYbbfWDOBQKqaKiQpFIRJdddpnq6+ttdXmorq5Ohw4d6nNGbBeTJ0/WG2+8odLSUp04cUIrV65URUWF9u7dq8svv9zqeElpa2vTxo0btXDhQi1evFhffPGFlixZIkl69NFHLU6Xmh07dujw4cO6//77rY6StMWLF6urq0tTpkxRdna2enp69MQTT+jhhx9O+74pkjR45plntHfvXn300Ue2us5dWlqq3bt36+TJkwoEAlqwYIGam5tVXl5udbSEwuGwli9frg8//FA5OTlWx0nZmWeNkydP1s0336zGxkYtWrTIolSpicVimjhxol544QVJ0k033aRDhw5pw4YNtiuSuro6TZo0SRMmTLA6StK2bdsmv9+vDRs2aPz48friiy/09NNPa/To0frxj3+c1n1TJANs6dKl2rZtm5qammx1fViScnJyNHbsWEnSxIkT9dlnn+mNN97Q66+/bnGyxPbt26eOjg7deuutvcui0aj27NmjTZs26auvvtLQoUMtTJia4cOHa/z48Tp06JDVUZJWVFSk6667rs+ysrIyHT161KJEF6a9vV0ffPCBVq1aZXWUlDz//PNatGiR7rnnHknffj32kSNH9Pvf/54isZMlS5Zo27Ztam5utuWjm2eKxWI6ffq01TGSMmvWLE2cOLHPsscee0wlJSV6/PHHbTdLiUQiCofDuuOOO6yOkrSpU6fq4MGDfZYdPHhQxcXFFiW6MA0NDRo6dKjmzJljdZSUdHd3n3UFJDs7W7FYLO37HlRF0tXV1XsG9v/fDT9q1KhB/5/xiSee0B//+EfV19crLy9Px48flyRddtllGj58uMXpEnvxxRdVUVGhq6++Wl1dXXrnnXfU2tqqLVu2WB0tKd898///cnNzNWrUKFtcmnv22Wd111136Zprrum9R9Ld3a158+ZZHS1pCxcuVEVFhVatWqU5c+bowIEDWrdunZ577jmroyUtHo/rrbfe0pw5czRixAir46Tkrrvu0quvvqprr71W48eP14EDB/SHP/xBPp8v7fseVL9Gfvfu3X2+G/47dvhu+PM9nbVkyRItXbo0w2lSt2DBAu3evVtff/21Ro4cKbfbrZ/97GeaPn261dEu2KxZs1ReXq6VK1daHSWh+fPna8+ePero6FBBQYEmT56sX/ziFxo/frzV0VKyfft2LV++XAcPHtQ111yjRx55RD/96U+VlZVldbSk7Nq1S1VVVfrkk0/k8XisjpOSf//73/rVr36l5uZmnThxQkVFRbrnnnv01FNPyeVypXXfg6pIAAD2w+dIAABGKBIAgBGKBABghCIBABihSAAARigSAIARigQAYIQiAQAYoUgAAEb+C5+5npgdOqozAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting the points\n",
    "[[plt.scatter(ii[0],ii[1],s=100,c=i) for ii in dataset[i]] for i in dataset]\n",
    "plt.scatter(new_features[0],new_features[1],s=50,c=result[0])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying on Forest Types Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_minus_obs_H_b9</th>\n",
       "      <th>pred_minus_obs_S_b1</th>\n",
       "      <th>pred_minus_obs_S_b2</th>\n",
       "      <th>pred_minus_obs_S_b3</th>\n",
       "      <th>pred_minus_obs_S_b4</th>\n",
       "      <th>pred_minus_obs_S_b5</th>\n",
       "      <th>pred_minus_obs_S_b6</th>\n",
       "      <th>pred_minus_obs_S_b7</th>\n",
       "      <th>pred_minus_obs_S_b8</th>\n",
       "      <th>pred_minus_obs_S_b9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d</td>\n",
       "      <td>39</td>\n",
       "      <td>36</td>\n",
       "      <td>57</td>\n",
       "      <td>91</td>\n",
       "      <td>59</td>\n",
       "      <td>101</td>\n",
       "      <td>93</td>\n",
       "      <td>27</td>\n",
       "      <td>60</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.36</td>\n",
       "      <td>-18.41</td>\n",
       "      <td>-1.88</td>\n",
       "      <td>-6.43</td>\n",
       "      <td>-21.03</td>\n",
       "      <td>-1.60</td>\n",
       "      <td>-6.18</td>\n",
       "      <td>-22.50</td>\n",
       "      <td>-5.20</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>h</td>\n",
       "      <td>84</td>\n",
       "      <td>30</td>\n",
       "      <td>57</td>\n",
       "      <td>112</td>\n",
       "      <td>51</td>\n",
       "      <td>98</td>\n",
       "      <td>92</td>\n",
       "      <td>26</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.26</td>\n",
       "      <td>-16.27</td>\n",
       "      <td>-1.95</td>\n",
       "      <td>-6.25</td>\n",
       "      <td>-18.79</td>\n",
       "      <td>-1.99</td>\n",
       "      <td>-6.18</td>\n",
       "      <td>-23.41</td>\n",
       "      <td>-8.87</td>\n",
       "      <td>-10.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s</td>\n",
       "      <td>53</td>\n",
       "      <td>25</td>\n",
       "      <td>49</td>\n",
       "      <td>99</td>\n",
       "      <td>51</td>\n",
       "      <td>93</td>\n",
       "      <td>84</td>\n",
       "      <td>26</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.46</td>\n",
       "      <td>-15.92</td>\n",
       "      <td>-1.79</td>\n",
       "      <td>-4.64</td>\n",
       "      <td>-17.73</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-4.69</td>\n",
       "      <td>-19.97</td>\n",
       "      <td>-4.10</td>\n",
       "      <td>-7.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s</td>\n",
       "      <td>59</td>\n",
       "      <td>26</td>\n",
       "      <td>49</td>\n",
       "      <td>103</td>\n",
       "      <td>47</td>\n",
       "      <td>92</td>\n",
       "      <td>82</td>\n",
       "      <td>25</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>2.68</td>\n",
       "      <td>-13.77</td>\n",
       "      <td>-2.53</td>\n",
       "      <td>-6.34</td>\n",
       "      <td>-22.03</td>\n",
       "      <td>-2.34</td>\n",
       "      <td>-6.60</td>\n",
       "      <td>-27.10</td>\n",
       "      <td>-7.99</td>\n",
       "      <td>-10.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d</td>\n",
       "      <td>57</td>\n",
       "      <td>49</td>\n",
       "      <td>66</td>\n",
       "      <td>103</td>\n",
       "      <td>64</td>\n",
       "      <td>106</td>\n",
       "      <td>114</td>\n",
       "      <td>28</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.94</td>\n",
       "      <td>-21.74</td>\n",
       "      <td>-1.64</td>\n",
       "      <td>-4.62</td>\n",
       "      <td>-23.74</td>\n",
       "      <td>-0.85</td>\n",
       "      <td>-5.50</td>\n",
       "      <td>-22.83</td>\n",
       "      <td>-2.74</td>\n",
       "      <td>-5.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class  b1  b2  b3   b4  b5   b6   b7  b8  b9         ...           \\\n",
       "0    d   39  36  57   91  59  101   93  27  60         ...            \n",
       "1    h   84  30  57  112  51   98   92  26  62         ...            \n",
       "2    s   53  25  49   99  51   93   84  26  58         ...            \n",
       "3    s   59  26  49  103  47   92   82  25  56         ...            \n",
       "4    d   57  49  66  103  64  106  114  28  59         ...            \n",
       "\n",
       "   pred_minus_obs_H_b9  pred_minus_obs_S_b1  pred_minus_obs_S_b2  \\\n",
       "0                -2.36               -18.41                -1.88   \n",
       "1                -2.26               -16.27                -1.95   \n",
       "2                -1.46               -15.92                -1.79   \n",
       "3                 2.68               -13.77                -2.53   \n",
       "4                -2.94               -21.74                -1.64   \n",
       "\n",
       "   pred_minus_obs_S_b3  pred_minus_obs_S_b4  pred_minus_obs_S_b5  \\\n",
       "0                -6.43               -21.03                -1.60   \n",
       "1                -6.25               -18.79                -1.99   \n",
       "2                -4.64               -17.73                -0.48   \n",
       "3                -6.34               -22.03                -2.34   \n",
       "4                -4.62               -23.74                -0.85   \n",
       "\n",
       "   pred_minus_obs_S_b6  pred_minus_obs_S_b7  pred_minus_obs_S_b8  \\\n",
       "0                -6.18               -22.50                -5.20   \n",
       "1                -6.18               -23.41                -8.87   \n",
       "2                -4.69               -19.97                -4.10   \n",
       "3                -6.60               -27.10                -7.99   \n",
       "4                -5.50               -22.83                -2.74   \n",
       "\n",
       "   pred_minus_obs_S_b9  \n",
       "0                 1.00  \n",
       "1               -10.83  \n",
       "2                -7.07  \n",
       "3               -10.81  \n",
       "4                -5.84  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the Forest Types Training Dataset\n",
    "df_tr = pd.read_csv('../training.csv') #Dataframe for training.csv\n",
    "class_tr = df_tr['class'].unique()  #classes for training.csv\n",
    "df_tr.head()                        #printing dataframe for training.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_minus_obs_H_b9</th>\n",
       "      <th>pred_minus_obs_S_b1</th>\n",
       "      <th>pred_minus_obs_S_b2</th>\n",
       "      <th>pred_minus_obs_S_b3</th>\n",
       "      <th>pred_minus_obs_S_b4</th>\n",
       "      <th>pred_minus_obs_S_b5</th>\n",
       "      <th>pred_minus_obs_S_b6</th>\n",
       "      <th>pred_minus_obs_S_b7</th>\n",
       "      <th>pred_minus_obs_S_b8</th>\n",
       "      <th>pred_minus_obs_S_b9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d</td>\n",
       "      <td>67</td>\n",
       "      <td>51</td>\n",
       "      <td>68</td>\n",
       "      <td>115</td>\n",
       "      <td>69</td>\n",
       "      <td>111</td>\n",
       "      <td>136</td>\n",
       "      <td>31</td>\n",
       "      <td>67</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.17</td>\n",
       "      <td>-18.27</td>\n",
       "      <td>-1.80</td>\n",
       "      <td>-6.32</td>\n",
       "      <td>-20.88</td>\n",
       "      <td>-1.63</td>\n",
       "      <td>-6.13</td>\n",
       "      <td>-22.56</td>\n",
       "      <td>-5.53</td>\n",
       "      <td>-8.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s</td>\n",
       "      <td>67</td>\n",
       "      <td>28</td>\n",
       "      <td>51</td>\n",
       "      <td>99</td>\n",
       "      <td>50</td>\n",
       "      <td>97</td>\n",
       "      <td>82</td>\n",
       "      <td>26</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.25</td>\n",
       "      <td>-20.13</td>\n",
       "      <td>-2.11</td>\n",
       "      <td>-6.35</td>\n",
       "      <td>-21.94</td>\n",
       "      <td>-1.22</td>\n",
       "      <td>-6.13</td>\n",
       "      <td>-22.20</td>\n",
       "      <td>-3.41</td>\n",
       "      <td>-6.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s</td>\n",
       "      <td>63</td>\n",
       "      <td>26</td>\n",
       "      <td>50</td>\n",
       "      <td>95</td>\n",
       "      <td>49</td>\n",
       "      <td>91</td>\n",
       "      <td>81</td>\n",
       "      <td>26</td>\n",
       "      <td>57</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>-17.64</td>\n",
       "      <td>-1.81</td>\n",
       "      <td>-4.70</td>\n",
       "      <td>-19.39</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>-5.01</td>\n",
       "      <td>-20.89</td>\n",
       "      <td>-3.96</td>\n",
       "      <td>-6.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d</td>\n",
       "      <td>63</td>\n",
       "      <td>42</td>\n",
       "      <td>63</td>\n",
       "      <td>97</td>\n",
       "      <td>66</td>\n",
       "      <td>108</td>\n",
       "      <td>111</td>\n",
       "      <td>28</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.34</td>\n",
       "      <td>-20.20</td>\n",
       "      <td>-1.89</td>\n",
       "      <td>-5.47</td>\n",
       "      <td>-21.65</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>-5.71</td>\n",
       "      <td>-22.19</td>\n",
       "      <td>-3.41</td>\n",
       "      <td>-6.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s</td>\n",
       "      <td>46</td>\n",
       "      <td>27</td>\n",
       "      <td>50</td>\n",
       "      <td>83</td>\n",
       "      <td>51</td>\n",
       "      <td>90</td>\n",
       "      <td>76</td>\n",
       "      <td>26</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>1.25</td>\n",
       "      <td>-18.62</td>\n",
       "      <td>-2.17</td>\n",
       "      <td>-7.11</td>\n",
       "      <td>-21.12</td>\n",
       "      <td>-1.56</td>\n",
       "      <td>-6.35</td>\n",
       "      <td>-22.19</td>\n",
       "      <td>-4.45</td>\n",
       "      <td>-7.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class  b1  b2  b3   b4  b5   b6   b7  b8  b9         ...           \\\n",
       "0    d   67  51  68  115  69  111  136  31  67         ...            \n",
       "1    s   67  28  51   99  50   97   82  26  59         ...            \n",
       "2    s   63  26  50   95  49   91   81  26  57         ...            \n",
       "3    d   63  42  63   97  66  108  111  28  59         ...            \n",
       "4    s   46  27  50   83  51   90   76  26  56         ...            \n",
       "\n",
       "   pred_minus_obs_H_b9  pred_minus_obs_S_b1  pred_minus_obs_S_b2  \\\n",
       "0                -9.17               -18.27                -1.80   \n",
       "1                -2.25               -20.13                -2.11   \n",
       "2                -0.44               -17.64                -1.81   \n",
       "3                -2.34               -20.20                -1.89   \n",
       "4                 1.25               -18.62                -2.17   \n",
       "\n",
       "   pred_minus_obs_S_b3  pred_minus_obs_S_b4  pred_minus_obs_S_b5  \\\n",
       "0                -6.32               -20.88                -1.63   \n",
       "1                -6.35               -21.94                -1.22   \n",
       "2                -4.70               -19.39                -0.65   \n",
       "3                -5.47               -21.65                -0.99   \n",
       "4                -7.11               -21.12                -1.56   \n",
       "\n",
       "   pred_minus_obs_S_b6  pred_minus_obs_S_b7  pred_minus_obs_S_b8  \\\n",
       "0                -6.13               -22.56                -5.53   \n",
       "1                -6.13               -22.20                -3.41   \n",
       "2                -5.01               -20.89                -3.96   \n",
       "3                -5.71               -22.19                -3.41   \n",
       "4                -6.35               -22.19                -4.45   \n",
       "\n",
       "   pred_minus_obs_S_b9  \n",
       "0                -8.11  \n",
       "1                -6.57  \n",
       "2                -6.85  \n",
       "3                -6.52  \n",
       "4                -7.32  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the Forest Types Testing Dataset\n",
    "df_ts = pd.read_csv('../testing.csv') #Dataframe for testing.csv\n",
    "class_ts = df_ts['class'].unique()  #classes for testing.csv\n",
    "df_ts.head()                        #printing dataframe for testing.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the dataframes to lists\n",
    "train_data = df_tr.values.tolist()  #Training data coverted to list \n",
    "test_data = df_ts.values.tolist()  #Testing data coverted to list \n",
    "\n",
    "# shuffling the records for train and test data\n",
    "random.shuffle(train_data)\n",
    "random.shuffle(test_data)\n",
    "\n",
    "\n",
    "# Data set comes splitted into train(62%) and test sets(38%)\n",
    "train_set = {class_tr[0]:[],class_tr[1]:[],class_tr[2]:[],class_tr[3]:[]}\n",
    "test_set = {class_ts[0]:[],class_ts[1]:[],class_ts[2]:[],class_ts[3]:[]}\n",
    "\n",
    "\n",
    "#Filling the training and testing datasets\n",
    "for i in train_data:    \n",
    "    train_set[i[0]].append(i[1:])  \n",
    "for i in test_data:\n",
    "    test_set[i[0]].append(i[1:])\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the accuracy. Also displaying the confidence in case of incorrect prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with k=5: 0.8215384615384616\n",
      "Accuracy with k=7: 0.8184615384615385\n",
      "Accuracy with k=9: 0.8174358974358974\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for group in test_set:\n",
    "    for data in test_set[group]:\n",
    "        vote, confidence = knn(train_set,data,k=5)\n",
    "        if vote==group:\n",
    "            correct +=1\n",
    "        #else:\n",
    "            #print(confidence)\n",
    "        total +=1\n",
    "\n",
    "print('Accuracy with k=5:',correct/total)\n",
    "\n",
    "\n",
    "for group in test_set:\n",
    "    for data in test_set[group]:\n",
    "        vote, confidence = knn(train_set,data,k=7)\n",
    "        if vote==group:\n",
    "            correct +=1\n",
    "        #else:\n",
    "            #print(confidence)\n",
    "        total +=1\n",
    "\n",
    "print('Accuracy with k=7:',correct/total)\n",
    "\n",
    "for group in test_set:\n",
    "    for data in test_set[group]:\n",
    "        vote, confidence = knn(train_set,data,k=9)\n",
    "        if vote==group:\n",
    "            correct +=1\n",
    "        #else:\n",
    "            #print(confidence)\n",
    "        total +=1\n",
    "\n",
    "print('Accuracy with k=9:',correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
